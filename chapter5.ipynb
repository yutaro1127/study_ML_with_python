{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross varidation 交差検証  \n",
    "- モデルを作る上で重要な指標の一つに汎化性能がある。なぜなら、モデルを作るモチベーションは何かを予測したい、であり、予測するデータは未知なデータなので。\n",
    "- モデルを作るために準備した特長量と、それに適用する予測器のアルゴリズムがどの程度汎化性能を持っているかどうかは、testデータに対するscoreで見ていたが、train testの分け方はランダムなので、1回の思考でいいのか？という観点。\n",
    "## k-fold k分割, stratified k-fold 層化k分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(max_iter=2000)\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'average of cross val score : {np.average(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- クロスバリデーションはモデルを返さない。  \n",
    "モデルを作るための手法ではなく、与えたデータセットに対して指定したアルゴリズム（今回で言えばロジスティック回帰）がどの程度汎化できるかの目安を見るだけ。  \n",
    "今回の例で言えば、irisのデータセットは、ロジスティック回帰で大体97%の割合で品種を当てられそうだ、ということがわかった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 単純なk分割交差だと、データセットの並び順によって分割されたデータセット内の目的変数にばらつきが生じる可能性がある  \n",
    "* クラス分割の場合は、目的変数ごとに等分する層化k分割交差検証をした方がいい  \n",
    "* sklearnはestimaterがクラス分類器の場合は層化、回帰器の場合は通常のk分割をデフフォルトで採用してくれる。\n",
    "* 分割器をimportしてcvパラメータに明示的に指定することも可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_stratified_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# irisデータセットに層化しない3分割交差検証をすると、訓練したデータセット内にテストの目的変数がないため精度はゼロ\n",
    "logreg=LogisticRegression(max_iter=2000)\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=KFold(n_splits=3))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単純分割でもデータセットをすれば確率的にばらける\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=KFold(n_splits=3,shuffle=True,random_state=0))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# 層化の方が安定\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=StratifiedKFold(n_splits=3))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1つ抜き交差検証\n",
    "- データセットから1つをテストデータとして、それ以外のデータで訓練したモデルを使って残りの一つを当てる、というのを総当たりで繰り返して汎化性能を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=LeaveOneOut())\n",
    "print(f'number of cv iter : {len(scores)}')\n",
    "print(f'avg of scores : {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle split シャッフル分割\n",
    "- データセットからn_tr個 or f_tr%の訓練データと、それに重複しないn_te個 or f_te%のテストデータを取り出してscoreを求めることをn_split回実行する、というやり方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_shuffle_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle=ShuffleSplit(train_size=.5,test_size=.5,n_splits=10,random_state=42) # 50％ずつ訓練とテストに分けてscore算出を10回繰り返す\n",
    "scores=cross_val_score(estimator=logreg,X=iris.data,y=iris.target,cv=shuffle)\n",
    "print(f'number of split : {len(scores)}')\n",
    "print(f'avg of scores : {scores.mean()}')\n",
    "# 層化シャッフル分割もある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グループ付交差検証\n",
    "- 例えば100人から10枚ずつ集めた写真をデータセットとして、表情から感情を当てる予測器を作るとき、予測器に求められる汎化性能は、「訓練データに入っていない人の新しい表情から感情を当てること」。一方で、予測の視点で言えば、訓練した人の新しい表情から感情を当てる方が簡単。  \n",
    "このため、交差検証において、訓練データとテストデータに同じ人の画像が入っていると、精度が高くでがち。  \n",
    "これを防ぐために、同じ人、というグループの概念を加味して分割する。\n",
    "  - 具体的には、同じグループのデータは訓練とテストのいずれかにまとまるように分割する\n",
    "    - 現実世界でこういうケースは多く、同じ患者から得られた複数サンプルをもとにモデルを作る（汎化性能は未知の人の予測）とか、同じ人から得られた発話をもとにモデルを作る、とか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_group_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.datasets import make_blobs\n",
    "X,y=make_blobs(n_samples=12,random_state=0)\n",
    "groups = [0,0,0,1,1,1,1,2,2,3,3,3]\n",
    "# サンプルサイズ12のデータは、4グループに属している、というデータの例\n",
    "\n",
    "scores=cross_val_score(estimator=logreg,X=X,y=y,groups=groups,cv=GroupKFold(n_splits=3))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グリッドサーチ\n",
    "- 汎化性能に影響する因子として、特長量、アルゴリズムの種類に加えて、ハイパーパラメータがある。\n",
    "- パラメータのチューニングは大変。sklearnではそれをフォローするアルゴリズムとしてグリッドサーチを実装。\n",
    "- パラメータの全ての組み合わせを試す方法\n",
    "- RBFカーネル法を使ったSVMで例示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_svm(log_C=-1,log_gamma=0)\n",
    "\"\"\"\n",
    "RBFカーネル法のSVMのおさらい\n",
    "パラメータは2つ\n",
    "gamma : データポイントが近い、とみなす距離を制御。\n",
    "    小さい＝寛大な判定。そんな近くなくても近い\n",
    "    大きい＝厳しい判定。ちゃんと近くないと近くない\n",
    "C : 正則化パラメータ：1つ1つのデータポイントの重要度を制御。\n",
    "    小さい＝強い正則化。一つひとつのデータポイントの重要度を下げる（精度は劣るが汎化に優れる）。\n",
    "    大きい：弱い正則化。全てのデータポイントにしっかり向き合って予測（過学習のリスク\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単純なグリッドサーチ\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=0)\n",
    "best_score=0\n",
    "\n",
    "for gamma in [.001,.01,.1,1,10,100]:\n",
    "    for C in [.001,.01,.1,1,10,100]:\n",
    "        svc=SVC(gamma=gamma,C=C).fit(X_train,y_train)\n",
    "        score=svc.score(X_test,y_test)\n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            best_param={'gamma':gamma,'C':C}\n",
    "print(best_score)\n",
    "print(best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- これはだめ\n",
    "- trainでモデル構築してtestでパラメータチューニングしてしまったので、作ったモデルが未知のデータに対してどんな性能を示すかが検証できていない\n",
    "- パラメータチューニングによってtestデータを過学習したモデルを作っている\n",
    "  - データに都合いいモデルは組めたけど、未知のデータもこれに当てはまるかわからないよね？ -> trainでfittingしてtestで確認しましょう\n",
    "  - 訓練データを使って、とっておいた残りのデータにも割と当てはまるモデルができた！\n",
    "    - パラメータをいじってもっといい感じにしたいけど、残りのデータを全部使ってパラメータをいじったら、たまたまそのデータに都合いいだけのパラメータだったかもしれない  \n",
    "    -> validationでtuningしてtestで確認しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_threefold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val,X_test,y_train_val,y_test=train_test_split(iris.data,iris.target,random_state=0)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train_val,y_train_val,random_state=1)\n",
    "best_score=0\n",
    "\n",
    "\n",
    "\n",
    "for gamma in [.001,.01,.1,1,10,100]:\n",
    "    for C in [.001,.01,.1,1,10,100]:\n",
    "        svc=SVC(gamma=gamma,C=C).fit(X_train,y_train) #訓練データで作ったモデルを\n",
    "        score=svc.score(X_val,y_val) #バリデーションデータでチューニング\n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            best_param={'gamma':gamma,'C':C}\n",
    "print(f'best score on validation : {best_score}')\n",
    "print(f'best params : {best_param}')\n",
    "\n",
    "svc=SVC(gamma=best_param['gamma'],C=best_param['C']).fit(X_train_val,y_train_val) #訓練データとバリデーションデータでモデルを再構築\n",
    "score = svc.score(X_test,y_test)\n",
    "print(f'score on test : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交差検証✖️グリッドサーチ\n",
    "- データの分け方によって最適パラメータが変わったりするので、クロスバリデーションした方が確か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in [.001,.01,.1,1,10,100]:\n",
    "    for C in [.001,.01,.1,1,10,100]:\n",
    "        svc=SVC(gamma=gamma,C=C) #訓練データで作ったモデルを\n",
    "        scores=cross_val_score(estimator=svc,X=X_train_val,y=y_train_val,cv=5)\n",
    "        score=scores.mean()\n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            best_param={'gamma':gamma,'C':C}\n",
    "print(f'best score on validation : {best_score}')\n",
    "print(f'best params : {best_param}')\n",
    "\n",
    "svc=SVC(gamma=best_param['gamma'],C=best_param['C']).fit(X_train_val,y_train_val) #訓練データとバリデーションデータでモデルを再構築\n",
    "score = svc.score(X_test,y_test)\n",
    "print(f'score on test : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_cross_val_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 広義では交差検証はデータセットに対するアルゴリズムの汎化性能を評価する手法だが、現実的にはパラメータチューニングの際のグリッドサーチに交差検証を使うケースがほとんどなので、一般に交差検証＝交差検証を使ったグリッドサーチによるパラメータチューニングという意味で使われることが多い  \n",
    "- 交差検証をする場合は、train-testに分けて、train内で交差検証をすれば良いので、validationデータを明示的に分けなくてOK  \n",
    "- sklearnでは交差検証を用いたグリッドサーチによるパラメータチューニングのためにGridSearchCVクラスがある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'gamma':[.001,.01,.1,1,10,100],\n",
    "    'C':[.001,.01,.1,1,10,100]\n",
    "}\n",
    "# GridSearchCVインスタンス作成\n",
    "# 引数は分類器のアルゴリズム、アルゴリズムに応じたパラメータとテストしたい値の辞書、クロスバリデーションの方法（分割数）\n",
    "grid_search=GridSearchCV(estimator=SVC(),param_grid=param_grid,cv=5)\n",
    "# このインスタンスはfitするだけで自動的にクロスバリデーションを実施して、最適なパラメータで再構築したモデルを返す。\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=0)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best score on cross validation {grid_search.best_score_:.3f}')\n",
    "print(f'best params {grid_search.best_params_}')\n",
    "print(f'accuracy on test {grid_search.score(X_test,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best estimator\\n{grid_search.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result=pd.DataFrame(grid_search.cv_results_).loc[:,'param_C':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,arg in enumerate(cv_result.columns):\n",
    "    print(f'{i:<2}:{arg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result[cv_result.columns[[0,1,8,9,10]]].sort_values('rank_test_score',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=np.array(cv_result.mean_test_score).reshape(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=cv_result.pivot(index='param_C',columns='param_gamma',values='mean_test_score').sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.heatmap(result,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 今回はうまくいったが、パラメータの検証はばが小さいと全部ダメダメだったりすることも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_liner = {\n",
    "    'gamma':np.linspace(1,2,6),\n",
    "    'C':np.linspace(1,2,6),\n",
    "}\n",
    "param_grid_one_log = {\n",
    "    'gamma':np.logspace(-3,2,6),\n",
    "    'C':np.linspace(1,2,6),\n",
    "}\n",
    "param_grid_log = {\n",
    "    'gamma':np.logspace(-1,4,6),\n",
    "    'C':np.logspace(-3,2,6),\n",
    "}\n",
    "\n",
    "fig,axes =plt.subplots(1,3,figsize=(15,5),tight_layout=True)\n",
    "\n",
    "for ax,param_grid in zip(axes,[param_grid_liner,param_grid_one_log,param_grid_log]):\n",
    "    grid_search=GridSearchCV(estimator=SVC(),param_grid=param_grid,cv=5)\n",
    "    X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=0)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    result=pd.DataFrame(grid_search.cv_results_)\n",
    "    result=result.pivot(index='param_C',columns='param_gamma',values='mean_test_score').sort_index(ascending=False)\n",
    "    sns.heatmap(result,annot=True,ax=ax,vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 総当たりだけでなく、組み合わせも指定できる、param_aがhogeの場合はparam_bとparam_c,param_aがfugaの場合はparam_dとparam_eみたいな"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid=[\n",
    "    {\n",
    "        'kernel':['rbf'], # 辞書のvalueはリスト型の必要あり\n",
    "        'gamma':[.001,.01,.1,1,10,100],\n",
    "        'C':[.001,.01,.1,1,10,100]\n",
    "    },\n",
    "    {\n",
    "        'kernel':['linear'],\n",
    "        'C':[.001,.01,.1,1,10,100]\n",
    "    }\n",
    "]\n",
    "grid_search=GridSearchCV(estimator=SVC(),param_grid=param_grid,cv=5)\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=0)\n",
    "grid_search.fit(X_train,y_train)\n",
    "# result=pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best score on cv : {grid_search.best_score_}')\n",
    "print(f'best params : {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ここまでのクロスバリデーションでは、訓練データの中の訓練データ/検証データの偏りを防いでいた。  \n",
    "複数のパラメータ条件を検証する際に、1つの条件検証内で何回もデータ分割を行う、という考え方。  \n",
    "  - しかし、そのための初手に訓練データとテストデータを１発分けているが、ここで偏りがあったらどうする・・・？  \n",
    "    - 初手のtrain&valid-testもクロスバリデーションして、それぞれのtraiｎ-validもクロスバリデーションすればOK！  \n",
    "    たくさんのデータセットでそれぞれパラメータチューニングをするので、最適なパラメータを求めているのではなく、モデル、パラメータまで込み込みの汎化性能を示す  \n",
    "    __データセットの評価の側面が大きい。このデータセットだったら、このアルゴリズムでパラメータチューニングを頑張ったら汎化性能が高いモデルが作れるね！ということがわかる__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(grid_search,X=iris.data,y=iris.target,cv=5,n_jobs=-1)\n",
    "print(f'cv scores : {scores}')\n",
    "print(f'mean cv scores : {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからはモデルの評価の話  \n",
    "- 元々のデータセットに偏りがあるとaccuracy(精度：テストサンプルのうちの正答率)が高くても、ちゃんと学習した優れたモデルといえないケースがある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(digits.data, y, random_state=0)\n",
    "\n",
    "from sklearn.dummy import  DummyClassifier\n",
    "dummy_majority=DummyClassifier(strategy='most_frequent').fit(X_train,y_train)\n",
    "pred_most_freq=dummy_majority.predict(X_test)\n",
    "# 訓練データの最頻クラスを返すだけの分類器\n",
    "print(f'accuracy on test by dummy : {dummy_majority.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=3,random_state=42).fit(X_train,y_train)\n",
    "pred_randomforest=rfc.predict(X_test)\n",
    "print(f'accuracy on test by random forest : {rfc.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy=DummyClassifier(strategy='prior').fit(X_train,y_train)\n",
    "pred_dummy=dummy.predict(X_test)\n",
    "print(f'dummy score : {dummy.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(max_iter=2000).fit(X_train,y_train)\n",
    "pred_logreg=logreg.predict(X_test)\n",
    "print(f'logreg score : {logreg.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混合行列:confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "confusion = confusion_matrix(y_test,pred_logreg)\n",
    "print(f'confusion matrix : \\n {confusion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_confusion_matrix_illustration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\n",
    "    'most freq':pred_most_freq,\n",
    "    'dummy':pred_dummy,\n",
    "    'random forest':pred_randomforest,\n",
    "    'logreg':pred_logreg\n",
    "}\n",
    "\n",
    "for k,v in d.items():\n",
    "    confusion=confusion_matrix(y_test,v)\n",
    "    print(f'{k}:\\n{confusion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __precision:適合率__ = モデルが陽性と判定したサンプルのうち本当に陽性だったサンプルの割合。的中率。モデルは陽性をどれだけ当てられたか。\n",
    "- __recall:再現率__ = 実際の陽性のうち、モデルが正しく陽性と判定したサンプルの割合。感度。真の陽性をどれくらい取りこぼさなかったか。\n",
    "- __F1スコア__ = precisionとrecallの調和平均。\n",
    "$$F1 score = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} = 2 \\times \\frac{precision + recall}{precision \\times recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "for k,v in d.items():\n",
    "    f1=f1_score(y_test,v)\n",
    "    print(f'{k:<20}:{f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    pred_logreg,\n",
    "    target_names=['not nine','nine']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不確実性を考慮\n",
    "- ２クラス分類の場合は、モデルの判定の不確実性を推定するための指標として以下の2つがある。\n",
    "  - dicision function(決定関数) : レンジは決まっていないが0以上なら陽性、以下なら陰性\n",
    "  - predict plobablity(確信度) : モデルが予測サンプルを陽性/陰性と判定した時のクラス分類の確率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X,y = make_blobs(n_samples=(400,50),cluster_std=[7.0,2],random_state=22)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n",
    "svc=SVC(gamma=.05).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y==0,0],X[y==0,1],marker='o',label=0)\n",
    "plt.scatter(X[y==1,0],X[y==1,1],marker='^',label=1)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class 1の再現率を高めたい、という目線で調整するとしたら、適合率が低くても良い（偽陽性が多くてもいい）ので取りこぼしがないように（偽陰性を少なくしたい）ということで決定関数を0以下にずらす。  \n",
    "そうするとモデルは1と判定しやすくなるので結果的に1の再現率は上がる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold = svc.decision_function(X_test)>-.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dicision_functionやpredict_probaをいじると適合率や再現率を操作することが可能だが、これらはトレードオフ。\n",
    "  - 例えば閾値を上げて厳しく判定させると、慎重に判断する分モデルの適合率は上がるが、陽性と回答する数が減るので取りこぼしが多くなり再現率は下がる\n",
    "  - 逆に閾値を下げて緩く判定させると、偽陰性が少なくなるので再現率は上がるが、大雑把に陽性だと判定するようになるので適合率は下がる\n",
    "## __これらのトレードオフを確認するために、precision-recall curveがある__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "ftp,recall,threshold=ftp_recall_curve(\n",
    "    y_test,\n",
    "    svc.decision_function(X_test)\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=ftp[1:],\n",
    "    y=recall[1:],\n",
    "    hue=threshold\n",
    ")\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを増やしてカーブを見てみる\n",
    "X,y=make_blobs(n_samples=(4000,500),cluster_std=[7.0,2],random_state=22)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n",
    "svc=SVC(gamma=.05).fit(X_train,y_train)\n",
    "precision,recall,threshold = precision_recall_curve(\n",
    "    y_test,\n",
    "    svc.decision_function(X_test)\n",
    ")\n",
    "close_zero=np.argmin(np.abs(threshold))\n",
    "\n",
    "plt.scatter(\n",
    "    precision[close_zero],\n",
    "    recall[close_zero],\n",
    "    marker='o',\n",
    "    # markersize=10,\n",
    "    # fillstyle=False,\n",
    "    c='k',\n",
    "    # mew=2,\n",
    "    label='threshold zero')\n",
    "plt.plot(\n",
    "    precision,\n",
    "    recall,\n",
    "    label='precision recall curve')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=3).fit(X_train,y_train)\n",
    "rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを増やしてカーブを見てみる\n",
    "svc=SVC(gamma=.05).fit(X_train,y_train)\n",
    "precision_svc,recall_svc,threshold_svc = precision_recall_curve(\n",
    "    y_test,\n",
    "    svc.decision_function(X_test)\n",
    ")\n",
    "close_zero=np.argmin(np.abs(threshold_svc))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,max_features=2,random_state=0).fit(X_train,y_train)\n",
    "precision_rfc,recall_rfc,threshold_rfc=precision_recall_curve(\n",
    "    y_test,\n",
    "    rfc.predict_proba(X_test)[:,1]\n",
    ")\n",
    "close_fifty=np.argmin(np.abs(threshold_rfc-.5))\n",
    "\n",
    "plt.plot(\n",
    "    precision_svc,\n",
    "    recall_svc,\n",
    "    label='precision recall curve by svc')\n",
    "\n",
    "plt.plot(\n",
    "    precision_rfc,\n",
    "    recall_rfc,\n",
    "    '--',\n",
    "    label='precision recall curve by randomforest')\n",
    "\n",
    "plt.scatter(\n",
    "    precision_svc[close_zero],\n",
    "    recall_svc[close_zero],\n",
    "    marker='o',\n",
    "    c='k',\n",
    "    label='threshold zero of svc')\n",
    "\n",
    "plt.scatter(\n",
    "    precision_rfc[close_fifty],\n",
    "    recall_rfc[close_fifty],\n",
    "    marker='^',\n",
    "    c='k',\n",
    "    label='threshold 0.5 of randomforest')\n",
    "\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- このカーブを検討するモデルに対して全部見るのはきついので、カーブの下側の面積を平均適合率として取り出して比較する見方もある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "avg_p_scv = average_precision_score(\n",
    "    y_true=y_test,\n",
    "    y_score=svc.decision_function(X_test)\n",
    ")\n",
    "\n",
    "avg_p_rfc = average_precision_score(\n",
    "    y_true=y_test,\n",
    "    y_score=rfc.predict_proba(X_test)[:,1]\n",
    ")\n",
    "\n",
    "print(f'avg precision of svc : {avg_p_scv:.2f}\\navg precision of random forest : {avg_p_rfc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もうひとつの不確実性確認　ROCカーブとAUC\n",
    "- ROC <ins>__R__</ins>eceiver <ins>__O__</ins>perating <ins>__C__</ins>haracteristic 受信者動作特性  \n",
    "ROCカーブはthresholdを変えた偽陽性率と真陽性率のプロット\n",
    "$$False Positice Rate = \\frac{False Positive}{True Negative \\times False Positive} = \\frac{本当は陰性なのに陽性にしてしまった}{陰性}$$\n",
    "$$True Positice Rate = \\frac{True Positive}{True Positive \\times False negative} = \\frac{陽性の予測があっていた}{陽性} = Recall$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,threshold = roc_curve(\n",
    "    y_test,\n",
    "    svc.decision_function(X_test)\n",
    ")\n",
    "close_zero=np.argmin(np.abs(threshold))\n",
    "\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    label='ROC svc')\n",
    "\n",
    "plt.scatter(\n",
    "    fpr[close_zero],\n",
    "    tpr[close_zero],\n",
    "    marker='o',\n",
    "    c='k',\n",
    "    label='threshold zero of svc')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROCカーブは、左上が理想。偽陽性を低く抑えながら真陽性を高くしたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(gamma=.05).fit(X_train,y_train)\n",
    "ftp_svc,recall_svc,threshold_svc = roc_curve(\n",
    "    y_test,\n",
    "    svc.decision_function(X_test)\n",
    ")\n",
    "close_zero=np.argmin(np.abs(threshold_svc))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,max_features=2,random_state=0).fit(X_train,y_train)\n",
    "ftp_rfc,recall_rfc,threshold_rfc=roc_curve(\n",
    "    y_test,\n",
    "    rfc.predict_proba(X_test)[:,1]\n",
    ")\n",
    "close_fifty=np.argmin(np.abs(threshold_rfc-.5))\n",
    "\n",
    "plt.plot(\n",
    "    ftp_svc,\n",
    "    recall_svc,\n",
    "    label='ROC curve by svc')\n",
    "\n",
    "plt.plot(\n",
    "    ftp_rfc,\n",
    "    recall_rfc,\n",
    "    '--',\n",
    "    label='ROC curve by randomforest')\n",
    "\n",
    "plt.scatter(\n",
    "    ftp_svc[close_zero],\n",
    "    recall_svc[close_zero],\n",
    "    marker='o',\n",
    "    c='k',\n",
    "    label='threshold zero of svc')\n",
    "\n",
    "plt.scatter(\n",
    "    ftp_rfc[close_fifty],\n",
    "    recall_rfc[close_fifty],\n",
    "    marker='^',\n",
    "    c='k',\n",
    "    label='threshold 0.5 of randomforest')\n",
    "\n",
    "plt.xlabel('False Positiive Rate')\n",
    "plt.ylabel('True Positive Rate (recall)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- precision recall curveと同じようにカーブの下側の面積を指標にする\n",
    "- <ins>A</ins>rea <ins>U</ins>nder the <ins>C</ins>urve = AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_scv = roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=svc.decision_function(X_test)\n",
    ")\n",
    "\n",
    "auc_rfc = roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=rfc.predict_proba(X_test)[:,1]\n",
    ")\n",
    "\n",
    "print(f'auc score of svc : {auc_scv:.2f}\\nauc score of random forest : {auc_rfc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target == 9\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    digits.data,\n",
    "    y,\n",
    "    random_state=0\n",
    ")\n",
    "for gamma in [1,.05,.01]:\n",
    "    svc=SVC(gamma=gamma).fit(X_train,y_train)\n",
    "    accuracy=svc.score(X_test,y_test)\n",
    "    auc=roc_auc_score(\n",
    "        y_test,\n",
    "        svc.decision_function(X_test)\n",
    "    )\n",
    "    print(f'gamma = {gamma:.2f}, accuracy = {accuracy:.2f}, auc score = {auc:.2f}')\n",
    "    fpr,tpr,threshold = roc_curve(\n",
    "        y_test,\n",
    "        svc.decision_function(X_test)\n",
    "    )\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f'gamma:{gamma}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ここまでは2クラス分類の話。これを他クラス分類に展開する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data,\n",
    "    digits.target,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "svc=SVC().fit(X_train,y_train)\n",
    "matrix=confusion_matrix(\n",
    "    y_test,\n",
    "    svc.predict(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    # xticklabels='predict',\n",
    "    # yticklabels='true'\n",
    "    )\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(max_iter=2000).fit(X_train,y_train)\n",
    "matrix=confusion_matrix(\n",
    "    y_test,\n",
    "    logreg.predict(X_test)\n",
    ")\n",
    "sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    cmap='Spectral_r'\n",
    "    # cmap='rocket_r'\n",
    ")\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('True')\n",
    "print(f'accuracy on test = {logreg.score(X_test,y_test):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    logreg.predict(X_test)\n",
    "))\n",
    "print(f'micro score {f1_score(y_test,logreg.predict(X_test),average=\"micro\"):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `f1-score`はそれぞれのクラスをpositive,ほかをnegativeの２値分類とした時のprecisionとrecallをもとに計算している。  \n",
    "- `macro avg`は上記のように算出した`precision`,`recall`,`f1_score`の単純平均値を示す。  \n",
    "クラス間にサンプルサイズの偏りがあったとしても、`macro avg`は重み付けしない単純な平均  \n",
    "- `weighted avg`は支度度(support=そのクラスに属するサンプル数)に応じた重み付け平均  \n",
    "クラス分類では一般的にはこれを見るらしい  \n",
    "- `micro score`は、支度度ではなく、<ins>全てのクラスの偽陽性、偽陰性、真陽性の総数</ins>を使って算出した値  \n",
    "ひとつひとつのサンプルを同様に重視する場合はこれを使うらしい・・・\n",
    "\n",
    "<ins>全てのクラスの偽陽性、偽陰性、真陽性の総数</ins> = モデルがpositiveといったサンプル(偽陽性＋真陽性) もしくは 実際のpositiveサンプル(偽陰性＋真陽性)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰の場合\n",
    "- 回帰については基本的に$R^2$でOKとのこと。  \n",
    "- モデル活用において(何かしらのビジネス決定を行うロジックとして)最小二乗誤差や平均絶対誤差を使う場合は、モデルのチューニングをこれらの誤差が小さくなるように実施すべきこともあるかも、らしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの選択時点でモデルの評価も加味してやりたい場合\n",
    "- モデルに最適なパラメータチューニングのためのGridSearchCVや、cross_cal_scoreは、accuracyを指標として使っていた\n",
    "- accuracyは使ったらあかん！という話だったのに...\n",
    "- sklearnなら、それぞれの引数にあるscoringに、基準となるスコア算出法を明示的に指定すればOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    cross_val_score(\n",
    "        SVC(),\n",
    "        digits.data,\n",
    "        digits.target==9,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    cross_val_score(\n",
    "        SVC(),\n",
    "        digits.data,\n",
    "        digits.target==9,\n",
    "        scoring='roc_auc'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data,digits.target == 9,random_state=0\n",
    ")\n",
    "\n",
    "def show_result(grid,X_test=X_test,y_test=y_test):\n",
    "    print(f'best param    = {grid.best_params_}')\n",
    "    print(f'best score    = {grid.best_score_:.3f}')\n",
    "    print(f'test accuracy = {grid.score(X_test,y_test):.3f}')\n",
    "    print(f'test auc      = {roc_auc_score(y_test,grid.decision_function(X_test)):.3f}')\n",
    "\n",
    "param_grid = {'gamma' : [.0001,.01,.1,1,10]}\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring='accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "print('accuracy')\n",
    "show_result(grid=grid)\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring='roc_auc')\n",
    "grid.fit(X_train,y_train)\n",
    "print('roc_auc')\n",
    "show_result(grid=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使えるスコアの一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics._scorer import _SCORERS\n",
    "\n",
    "def get_(list,num):\n",
    "    try:\n",
    "        return f'{num:<3}{list[num]:<30}'\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "print('使えるスコア一覧')\n",
    "l = list(_SCORERS.keys())\n",
    "for i in range(len(l)//3):\n",
    "    print(\n",
    "        f'{get_(l,3*i+1)}'\n",
    "        f'{get_(l,3*i+2)}'\n",
    "        f'{get_(l,3*i+3)}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_(_SCORERS.keys(),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
